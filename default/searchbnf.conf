# [searchbnf.conf](http://docs.splunk.com/Documentation/Splunk/latest/Admin/Searchbnfconf)

[fillbaseline-command]
syntax = fillbaseline config_name=<string> variable=<fieldname> [kv_store=<string>] <field-list>

shortdesc = Calculate basic statistics mad, max, mean, medcouple, median, min, pct25, pct75 and stdev aggregated by the field provided as variable parameter. \
            The calculated statistics are stored in a collection (default collection = hyperbaseline) and will be used by the comparetobaseline command for scoring. \
            Statistics are only calculated for numerical fields provided by field-list.

description = The following calculations are done by fillbaseline: \
                - min \
                - max \
                - mean \
                - median (50th percentile) \
                - pct25: 25th percentile (lower quartile) \
                - pct75: 75th percentile (upper quartile) \
                - stdev: standard deviation \
                - MAD: Median absolute deviation \
                - medcouple: a robust statistic that measures the skewness of a univariate distribution \
              These statistics are calculated for each value of the field provided as variable parameter and each field of the <field-list>. \
              The config_name parameter is used as a reference to enable the calculation of different search variations based on the same data. \

comment1 = Calculate the statistics based on the average, minimum and maximum splunk UI usage by day. \
           The statistics are calculated for each individual user:
example1 = index=_internal sourcetype=splunkd_ui_access| bucket span=1d _time \
           | stats avg(date_hour) as avg_hour min(date_hour) as min_hour max(date_hour) as max_hour by user _time \
           | fillbaseline config_name="ui_usage" value=user avg_hour min_hour max_hour

comment2 = Calculate the statistics based on user events connecting a USB drive during off hours. \
           As these off hour events tend to be spares you should fill the gaps in the timeseries using makecontinuous and fillnull commands:
example2 = index="insiderthreat" sourcetype="insiderthreat:device"  starttime="12/07/2010:00:00:00" endtime="01/06/2011:00:00:00" action=Connect (date_hour>=20 OR date_hour=<6) OR (date_wday="saturday" OR data_wday="sunday") \
           | bucket span=1d _time | chart limit=0 dc(user) as count over _time by user | makecontinuous _time span=1d | fillnull \
           | untable _time, user, count | fillbaseline config_name="connect_device" value=user count

category = reporting
appears-in = 6.0
maintainer = dittmanc
usage = public
related = stats
tags = SA_hyperbaseline


[comparetobaseline-command]
syntax = comparetobaseline config_name=<string> variable=<fieldname> [kv_store=<string>] [threshold=<float>] [method=ESD|Hampel|SBR|ASBR] [debug=<boolean>] <field-list>

shortdesc = Compare given values using statistical functions to identify an outlier. The 4 different outlier detection methods from \
            the FindOutlier package in R are available. \
            extreme Studentized deviation (ESD), Hampel, standard boxplot rule (SBR) and asymmetric standard boxplot rule (ASBR).

description = Comparetobaseline is using the calculated statistics from fillbaseline stored in the collection hyperbaseline or the collection provided by the parameter <kv_store>. \
              The default method to detect outliers is Hampel. The bounds for Hampel are [median - t * MAD, median + t * MAD] \
              Set threshold (t) to adjust the sensitivity. Higher values for threshold will lead to less outliers and lower threshold vice versa.\
              The default value for threshold for ESD and Hampel is 3 and for SBR and ASBR is 1.5. \
              ESD, Hampel and SBR do expect symmetrical distribution of data around mean/median. ASBR tries to adjust for asymmetrical data. \
              For further information please check http://www.r-bloggers.com/finding-outliers-in-numerical-data

comment1 = This search calculates scores for min_hour, avg_hour and max_hour based on the statistics stored in the hyperbaseline collection \
           previously calculate by fillbaseline. If you didn't execute fillbaseline before running comparebaseline search no score will be provided.
example1 = index=_internal sourcetype=splunkd_ui_access | bucket span=1d _time \
           | stats avg(date_hour) as avg_hour min(date_hour) as min_hour max(date_hour) as max_hour by user _time \
           | comparetobaseline config_name="ui_usage" variable="user" min_hour avg_hour max_hour

category = streaming
appears-in = 6.0
maintainer = dittmanc
usage = public
related = stats
tags = SA_hyperbaseline
